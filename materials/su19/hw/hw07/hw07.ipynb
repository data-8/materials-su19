{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw07.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Testing Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: \n",
    "* [Testing Hypotheses](https://www.inferentialthinking.com/chapters/11/testing-hypotheses.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "Homework 7 is due **Friday, 7/19 at 11:59pm**. You will receive an early submission bonus point if you turn in your final submission by Thursday, 7/18 at 11:59pm. Start early so that you can come to office hours if you're stuck. Check the website for the office hours schedule. Late work will not be accepted as per the [policies](http://data8.org/su19/policies.html) of this course. \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "For all problems that you must write our explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw07.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Catching Cheaters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a casino owner, and your casino runs a very simple game of chance.  The dealer flips a coin.  The customer wins $\\$$9 from the casino if it comes up heads and loses $\\$$10 if it comes up tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Assuming no one is cheating and the coin is fair, if a customer plays twice, what is the chance they make money?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_1"
   },
   "outputs": [],
   "source": [
    "p_winning_after_two_flips = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A certain customer plays the game 20 times and wins 13 of the bets.  You suspect that the customer is cheating!  That is, you think that their chance of winning is higher than the normal chance of winning.\n",
    "\n",
    "You decide to test your hunch using the outcomes of the 20 games you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Define the null hypothesis and alternative hypothesis for this investigation. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "for_assignment_type": "solution"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.** Which of the following test statistics would be a reasonable choice to help differentiate between the two hypotheses? You will see the outcome of 20 games.\n",
    "\n",
    "*Hint*: For a refresher on choosing test statistics, check out this section on [Test Statistics](https://www.inferentialthinking.com/chapters/11/3/decisions-and-uncertainty.html#Step-2:-The-Test-Statistic).\n",
    "\n",
    "1. Whether there is at least one win.\n",
    "1. Whether there is at least one loss.\n",
    "1. The number of wins.\n",
    "1. The number of wins minus 10.\n",
    "1. The total variation distance between the probability distribution of a fair coin and the observed distribution of heads and tails.\n",
    "1. The total amount of money that the customer won.\n",
    "\n",
    "Assign `reasonable_test_statistics` to an array of numbers corresponding to these test statistics.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reasonable_test_statistics = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "Suppose you decide to use the number of wins as your test statistic.\n",
    "\n",
    "**Question 4.** \n",
    "Write a function called `simulate` that generates exactly one simulated value of your test statistic under the null hypothesis.  It should take no arguments.  It should simulate 20 games under the assumption that the result of each game is sampled from a fair coin that lands heads or lands tails with 50% chance, and return the number of wins in those 20 games.\n",
    "\n",
    "*Hint*: You may find the textbook [section](https://www.inferentialthinking.com/chapters/11/1/Assessing_Models#predicting-the-statistic-under-the-model) on the `sample_proportions` function to be useful.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "fair_coin = ...\n",
    "def simulate():\n",
    "    ...\n",
    "    \n",
    "# Call your function to make sure it works\n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.** Generate 10,000 simulated values of the number of wins in 20 games. Assign `test_statistics_under_null` to an array that stores the result of each of these trials. \n",
    "\n",
    "*Hint*: Use the function you defined in Question 4.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_5\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "test_statistics_under_null = ...\n",
    "repetitions = ...\n",
    "\n",
    "...\n",
    "    \n",
    "test_statistics_under_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.** Using the results from Question 5, generate a histogram of the empirical distribution of the number of wins in 20 games.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_6\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "export_pdf": true,
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "\n",
    "**Question 7.** Compute an empirical P-value for this test.\n",
    "\n",
    "*Hint:* Would you expect large or small values of the test statistic under the alternative hypothesis?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_7\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "p_value = ...\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q1_7\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8.** Suppose you use a P-value cutoff of 1%. What do you conclude from the hypothesis test? Why?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_8"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 9.** Is `p_value` the probability that the customer cheated, or the probability that the customer didn't cheat, or neither? If neither, what is it?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_9\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_9"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 10.** Is 1% (the P-value cutoff) the probability that the customer cheated, or the probability that the customer didn't cheat, or neither? If neither, what is it?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_10\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_10"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 11.** Suppose you run this test for 400 different customers after observing each customer play 20 games.  When you reject the null hypothesis for a customer, you accuse that customer of cheating.  If no customers were actually cheating, can we compute how many we will incorrectly accuse of cheating? If so, what is the number? Explain your answer. Assume a 1% P-value cutoff.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_11\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_10"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Landing a Spacecraft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: This problem describes something that's close to [a real story with a very exciting video](http://www.space.com/29119-spacex-reusable-rocket-landing-crash-video.html), but the details have been changed somewhat.)\n",
    "\n",
    "SpaceY, a company that builds and tests spacecraft, is testing a new reusable launch system.  Most spacecraft use a \"first stage\" rocket that propels a smaller payload craft away from Earth, then falls back to the ground and crashes.  SpaceY's new system is designed to land safely at a landing pad at a certain location, ready for later reuse.  If it doesn't land in the right location, it crashes, and the very, very expensive vehicle is destroyed.\n",
    "\n",
    "SpaceY has tested this system over 1000 times.  Ordinarily, the vehicle doesn't land exactly on the landing pad.  For example, a gust of wind might move it by a few meters just before it lands.  It's reasonable to think of these small errors as random.  That is, the landing locations are drawn from some distribution over locations on the surface of Earth, centered around the landing pad.\n",
    "\n",
    "Run the next cell to see a plot of those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_landing_spots = Table.read_table(\"ordinary_landing_spots.csv\")\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Landing locations\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During one test, the vehicle lands far away from the landing pad and crashes.  SpaceY investigators suspect there was a problem unique to this landing, a problem that wasn't part of the ordinary pattern of variation in landing locations.  They think a software error in the guidance system caused the craft to incorrectly attempt to land at a spot other than the landing pad.  The guidance system engineers think there was nothing out of the ordinary in this landing, and that there was no special problem with the guidance system.\n",
    "\n",
    "Run the cell below to see a plot of the 1100 ordinary landings and the crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_spot = make_array(80.59, 30.91)\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Other landings\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.scatter(landing_spot.item(0), landing_spot.item(1), marker=\"*\", c=\"r\", s=1000, label=\"Crash site\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Let’s use distance from the landing pad as our test statistic, to compare the suspicious landing to the distribution of landings we believe to be normal.  Write a function called `landing_distance`.  It should take two arguments: an \"x\" location and a \"y\" location (both numbers), and should return the euclidean distance from the landing spot to the origin!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "manual_grade": true,
    "manual_problem_id": "landing_3"
   },
   "outputs": [],
   "source": [
    "def landing_distance(x_coordinate, y_coordinate):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2_1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Use the `landing_distance` function you wrote above to compute the landing distance for the crash site. Assign this distance to `observed_test_stat`.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_test_stat = ...\n",
    "observed_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2_2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.** Next, assign `distances` to an array containing the computed landing distances for each landing in `ordinary_landing_spots`. Use the `landing_distance` function you wrote above to compute these distances!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2_3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell below to see the points color-coded by distance! Gold points correspond to landing locations that are as far or farther away than the Crash Site!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots_with_distances = ordinary_landing_spots.with_column(\"Distances\", distances >= observed_test_stat)\n",
    "spots_with_distances.scatter('x', 'y', colors = 'Distances', label='Close Spots')\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.scatter(landing_spot.item(0), landing_spot.item(1), marker=\"*\", c=\"r\", s=1000, label=\"Crash site\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** What proportion of points were as far or farther away than the specific landing? Assign this value to `proportion_of_points` below. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_4\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_of_points = ...\n",
    "proportion_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2_4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.** How can we interpret the value of `proportion_of_points`? Assign `interpretations` to an array with the number(s) of all valid interpretations.\n",
    "1. There’s a `proportion_of_points` chance that this was an abnormal landing.\n",
    "2. There’s a 1 - `proportion_of_points` chance that this was a normal landing.\n",
    "3. If `proportion_of_points` is less than or equal to a predetermined cutoff, we can reject the hypothesis that this landing location came from the ordinary pattern of variation in landing locations.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_5\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpretations = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q2_5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students in a data science class want to figure out whether a six-sided die is fair or not. On a fair die, each face of the die appears with chance 1/6 on each roll, regardless of the results of other rolls.  Otherwise, a die is called unfair.  We can describe a die by the probability of landing on each face.  This table describes an example of a die that is unfairly weighted toward 1:\n",
    "\n",
    "|Face|Probability|\n",
    "|-|-|\n",
    "|1|.5|\n",
    "|2|.1|\n",
    "|3|.1|\n",
    "|4|.1|\n",
    "|5|.1|\n",
    "|6|.1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1.** Define a null hypothesis and an alternative hypothesis to test whether a six-sided die is fair or not. \n",
    "\n",
    "*Hint:* Remember that an unfair die is one for which each face does not have an equal chance of appearing.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "for_assignment_type": "solution"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to test the die by rolling it 5 times. The proportions of the 6 faces in these 5 rolls are stored in a table with 6 rows.  For example, here is the table we'd make if the die rolls ended up being 1, 2, 3, 3, and 5:\n",
    "\n",
    "|Face|Proportion|\n",
    "|-|-|\n",
    "|1|.2|\n",
    "|2|.2|\n",
    "|3|.4|\n",
    "|4|.0|\n",
    "|5|.2|\n",
    "|6|.0|\n",
    "\n",
    "The function `mystery_test_statistic`, defined below, takes a single table like this as its argument and returns a number (which we will use as a test statistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We've intentionally used unhelpful function and\n",
    "# variable names to avoid giving away answers.  It's rarely\n",
    "# a good idea to use names like \"x\" in your code.\n",
    "\n",
    "def mystery_test_statistic(sample):\n",
    "    x = np.ones(1) * (1/6)\n",
    "    y = (sample.column('Proportion') - x)\n",
    "    return np.mean(y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.** Describe in English what the test statistic is. Is it equivalent to the total variation distance between the observed face distribution and the fair die distribution, or is it a different statistic?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_2"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `simulate_observations_and_test` takes as its argument a table describing the probability distribution of a die.  It simulates one set of 5 rolls of that die, then tests the null hypothesis about that die using our test statistic function above.  It returns `False` if it *rejects* the null hypothesis about the die, and `True` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability distribution table for a fair die:\n",
    "fair_die = Table().with_columns(\n",
    "        \"Face\", np.arange(1,7),\n",
    "        \"Probability\", make_array(1/6, 1/6, 1/6, 1/6, 1/6, 1/6))\n",
    "\n",
    "def simulate_observations_and_test(actual_die):\n",
    "    \"\"\"Simulates die rolls from actual_die and tests the hypothesis that the die is fair.\n",
    "    \n",
    "    Returns False if that hypothesis is rejected, and True otherwise.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sample_size = 5\n",
    "    p_value_cutoff = .2\n",
    "    num_simulations = 250\n",
    "    \n",
    "    # Compute the observed value of the test statistic.\n",
    "    observation_set = sample_proportions(sample_size, actual_die.column(\"Probability\"))\n",
    "    observation_props_table = Table().with_columns('Face', actual_die.column('Face'), 'Proportion', observation_set)\n",
    "    observed_statistic = mystery_test_statistic(observation_props_table)\n",
    "    \n",
    "    # Simulate the test statistic repeatedly to get an \n",
    "    # approximation to the probability distribution of \n",
    "    # the test statistic, as predicted by the model in \n",
    "    # the null hypothesis. Store the simulated values \n",
    "    # of the test statistic in an array.\n",
    "    simulated_statistics = make_array()\n",
    "    for i in np.arange(num_simulations):\n",
    "        one_observation_set_under_null = sample_proportions(sample_size, fair_die.column(\"Probability\"))\n",
    "        simulated_props_table = Table().with_columns('Face', fair_die.column('Face'), 'Proportion', one_observation_set_under_null)\n",
    "        simulated_statistic = mystery_test_statistic(simulated_props_table)\n",
    "        simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "        \n",
    "    # Compute the P-value\n",
    "    p_value = np.count_nonzero(simulated_statistics >= observed_statistic) / num_simulations\n",
    "    \n",
    "    # If the P-value is below the cutoff, reject the \n",
    "    # null hypothesis and return False. Otherwise, \n",
    "    # return True.\n",
    "    return p_value >= p_value_cutoff\n",
    "\n",
    "# Calling the function to simulate a test of a fair die:\n",
    "simulate_observations_and_test(fair_die)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.** Use your knowledge of hypothesis tests and interpretation of the code above to determine the probability that `simulate_observations_and_test` returns `False` when its argument is `fair_die` (which is defined above the function). In other words, what is the chance that we reject the null hypothesis if the die is actually fair?\n",
    "\n",
    "You can call the function a few times to see what it does, but **don't** perform a simulation to determine this probability.  Use your knowledge of hypothesis tests. You shouldn't have to write any code to answer this question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_3\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_of_false = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3_3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4.** Justify your probability from Question 3.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_4\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_4"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5.** Simulate the process of running `simulate_observations_and_test` 300 times. Assign `test_results` to an array that stores the result of each of these trials.\n",
    "\n",
    "**Note:** This will be a little slow. 300 repetitions of the simulation should require a minute or so of computation, and should suffice to get an answer that's roughly correct.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_5\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "num_test_simulations = 300\n",
    "test_results = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Don't change the following line.\n",
    "test_results.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3_5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6.** Verify your answer to Question 3 by computing an approximate probability that `simulation_observations_and_test` returns `False`. You will need to use your result from Question 5.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_6\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_probability_of_false = ...\n",
    "approximate_probability_of_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q3_6\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7.** From the perspective of someone who wants to know the truth about the die, is it good or bad for the function to return `False` when its argument is `fair_die`? Why is it good or bad?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_7\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_grade": true,
    "manual_problem_id": "testing_dice_7"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-Semester Survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have submitted, please also take the time to complete the Mid-Semester Survey! We really appreciate your honest feedback and it helps us improve the course!\n",
    "\n",
    "The Mid Semester survey is here: https://forms.gle/prLM4ixJooWTjFXs6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the `submit` cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to [okpy.org](https://okpy.org/) and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q') and len(q) <= 10]\n",
    "print(\"Finished running all tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
